{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b449401-501f-460b-8290-ad65198915ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "051fb941-7ca7-48b6-9602-a0f29140c8fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# NOTEBOOK 3: SILVER TO GOLD - DIMENSIONAL MODEL BUILD\n",
    "\n",
    "# Purpose: Build Star Schema (Fact + Dimension tables) from Silver data\n",
    "\n",
    "\n",
    "# : Configuration\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "storage_account_name = \"your account name\"\n",
    "storage_account_key = \"your storage account key\"\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account_name}.dfs.core.windows.net\",\n",
    "    storage_account_key\n",
    ")\n",
    "\n",
    "silver_base_path = f\"abfss://silver@{storage_account_name}.dfs.core.windows.net\"\n",
    "gold_base_path = f\"abfss://gold@{storage_account_name}.dfs.core.windows.net\"\n",
    "\n",
    "print(\" Configuration complete!\")\n",
    "\n",
    "#  Load Silver Data\n",
    "\n",
    "print(\" Loading Silver layer data...\")\n",
    "\n",
    "# Load cleaned reviews\n",
    "df_reviews = spark.read.parquet(f\"{silver_base_path}/reviews_cleaned\")\n",
    "print(f\" Reviews loaded: {df_reviews.count():,} records\")\n",
    "\n",
    "# Load cleaned metadata\n",
    "df_metadata = spark.read.parquet(f\"{silver_base_path}/metadata_cleaned\")\n",
    "print(f\" Metadata loaded: {df_metadata.count():,} records\")\n",
    "\n",
    "\n",
    "# 3: Build Dimension - dim_date\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  Building dim_date (Date Dimension)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract unique dates from reviews\n",
    "df_dates = df_reviews.select(F.col(\"review_date\").cast(\"date\").alias(\"full_date\")).distinct()\n",
    "\n",
    "# Generate date attributes\n",
    "df_dim_date = df_dates \\\n",
    "    .withColumn(\"date_key\", F.date_format(F.col(\"full_date\"), \"yyyyMMdd\").cast(\"int\")) \\\n",
    "    .withColumn(\"year\", F.year(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"quarter\", F.quarter(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"month\", F.month(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"month_name\", F.date_format(F.col(\"full_date\"), \"MMMM\")) \\\n",
    "    .withColumn(\"week_of_year\", F.weekofyear(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"day_of_month\", F.dayofmonth(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"day_of_week\", F.dayofweek(F.col(\"full_date\"))) \\\n",
    "    .withColumn(\"day_name\", F.date_format(F.col(\"full_date\"), \"EEEE\")) \\\n",
    "    .withColumn(\"is_weekend\", F.when(F.col(\"day_of_week\").isin([1, 7]), True).otherwise(False)) \\\n",
    "    .orderBy(\"date_key\")\n",
    "\n",
    "print(f\" dim_date created: {df_dim_date.count():,} unique dates\")\n",
    "df_dim_date.show(10)\n",
    "\n",
    "# Write to Gold\n",
    "# df_dim_date.write.mode(\"overwrite\").parquet(f\"{gold_base_path}/dim_date\")\n",
    "\n",
    "df_dim_date.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base_path}/dim_date\")\n",
    "print(\" dim_date written to Gold layer\")\n",
    "\n",
    "# : Build Dimension - dim_categories\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Building dim_categories (Category Dimension)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get unique categories from metadata\n",
    "df_dim_categories = df_metadata.select(\"main_category\").distinct() \\\n",
    "    .withColumn(\"category_key\", F.monotonically_increasing_id().cast(\"int\")) \\\n",
    "    .withColumnRenamed(\"main_category\", \"category_name\") \\\n",
    "    .select(\"category_key\", \"category_name\")\n",
    "\n",
    "print(f\" dim_categories created: {df_dim_categories.count():,} categories\")\n",
    "df_dim_categories.show()\n",
    "\n",
    "# Write to Gold\n",
    "# df_dim_categories.write.mode(\"overwrite\").parquet(f\"{gold_base_path}/dim_categories\")\n",
    "df_dim_categories.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base_path}/dim_categories\")\n",
    "\n",
    "print(\" dim_categories written to Gold layer\")\n",
    "\n",
    "#  Build Dimension - dim_products\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  Building dim_products (Product Dimension)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Use metadata as base, enrich with review aggregates\n",
    "df_dim_products = df_metadata \\\n",
    "    .withColumn(\"product_key\", F.monotonically_increasing_id().cast(\"bigint\")) \\\n",
    "    .select(\n",
    "        \"product_key\",\n",
    "        \"parent_asin\",\n",
    "        \"title\",\n",
    "        \"price_cleaned\",\n",
    "        \"average_rating\",\n",
    "        \"rating_number\",\n",
    "        \"store\",\n",
    "        \"main_category\",\n",
    "        \"brand\",\n",
    "        \"features_text\",\n",
    "        \"description_text\"\n",
    "    )\n",
    "\n",
    "print(f\" dim_products created: {df_dim_products.count():,} products\")\n",
    "df_dim_products.show(5, truncate=True)\n",
    "\n",
    "# Write to Gold\n",
    "#df_dim_products.write.mode(\"overwrite\").parquet(f\"{gold_base_path}/dim_products\")\n",
    "df_dim_products.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base_path}/dim_products\")\n",
    "\n",
    "print(\" dim_products written to Gold layer\")\n",
    "\n",
    "\n",
    "# 6: Build Dimension - dim_users\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Building dim_users (User Dimension)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Aggregate user statistics from reviews\n",
    "df_dim_users = df_reviews.groupBy(\"user_id\").agg(\n",
    "    F.min(\"review_date\").alias(\"first_review_date\"),\n",
    "    F.count(\"*\").alias(\"total_reviews\"),\n",
    "    F.avg(\"rating\").alias(\"avg_rating_given\")\n",
    ") \\\n",
    ".withColumn(\"user_key\", F.monotonically_increasing_id().cast(\"bigint\")) \\\n",
    ".select(\n",
    "    \"user_key\",\n",
    "    \"user_id\",\n",
    "    \"first_review_date\",\n",
    "    \"total_reviews\",\n",
    "    F.round(\"avg_rating_given\", 2).alias(\"avg_rating_given\")\n",
    ")\n",
    "\n",
    "print(f\" dim_users created: {df_dim_users.count():,} users\")\n",
    "df_dim_users.show(10)\n",
    "\n",
    "# Write to Gold\n",
    "# df_dim_users.write.mode(\"overwrite\").parquet(f\"{gold_base_path}/dim_users\")\n",
    "df_dim_users.write.format(\"delta\").mode(\"overwrite\").save(f\"{gold_base_path}/dim_users\")\n",
    "\n",
    "print(\" dim_users written to Gold layer\")\n",
    "\n",
    "\n",
    "# : Build Fact Table - fact_reviews\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" Building fact_reviews (Fact Table - Star Schema Core!)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "\n",
    "dim_products = spark.read.format(\"delta\").load(f\"{gold_base_path}/dim_products\")\n",
    "dim_users = spark.read.format(\"delta\").load(f\"{gold_base_path}/dim_users\")\n",
    "dim_date = spark.read.format(\"delta\").load(f\"{gold_base_path}/dim_date\")\n",
    "dim_categories = spark.read.format(\"delta\").load(f\"{gold_base_path}/dim_categories\")\n",
    "\n",
    "# Prepare reviews with date_key\n",
    "df_reviews_with_datekey = df_reviews \\\n",
    "    .withColumn(\"date_key\", F.date_format(F.col(\"review_date\").cast(\"date\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "\n",
    "# Join to get product_key\n",
    "df_fact = df_reviews_with_datekey.join(\n",
    "    dim_products.select(\"product_key\", \"parent_asin\", \"main_category\"),\n",
    "    on=\"parent_asin\",\n",
    "    how=\"inner\"  # Inner join: only keep reviews with matching products\n",
    ")\n",
    "\n",
    "# Join to get user_key\n",
    "df_fact = df_fact.join(\n",
    "    dim_users.select(\"user_key\", \"user_id\"),\n",
    "    on=\"user_id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Join to get category_key\n",
    "df_fact = df_fact.join(\n",
    "    dim_categories.select(\"category_key\", F.col(\"category_name\").alias(\"main_category\")),\n",
    "    on=\"main_category\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Step 2: Create fact table with measures and foreign keys\n",
    "df_fact_reviews = df_fact \\\n",
    "    .withColumn(\"review_key\", F.monotonically_increasing_id().cast(\"bigint\")) \\\n",
    "    .select(\n",
    "        \"review_key\",           # Primary Key\n",
    "        \"product_key\",          # FK to dim_products\n",
    "        \"user_key\",             # FK to dim_users\n",
    "        \"date_key\",             # FK to dim_date\n",
    "        \"category_key\",         # FK to dim_categories\n",
    "        \"rating\",               # MEASURE\n",
    "        \"helpful_vote\",         # MEASURE\n",
    "        \"verified_purchase\",    # FACT (boolean)\n",
    "        \"review_text_length\",   # MEASURE\n",
    "        \"has_images\",           # FACT (boolean)\n",
    "        F.col(\"timestamp\").alias(\"review_timestamp\")  # Keep original timestamp\n",
    "    )\n",
    "\n",
    "print(f\" fact_reviews created: {df_fact_reviews.count():,} records\")\n",
    "df_fact_reviews.show(10)\n",
    "\n",
    "# Data validation: check for nulls in foreign keys (should be 0!)\n",
    "print(\"\\n Data Quality Check - Null Foreign Keys:\")\n",
    "df_fact_reviews.select([\n",
    "    F.sum(F.when(F.col(c).isNull(), 1).otherwise(0)).alias(f\"{c}_nulls\")\n",
    "    for c in [\"product_key\", \"user_key\", \"date_key\", \"category_key\"]\n",
    "]).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_fact_reviews.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"category_key\") \\\n",
    "    .save(f\"{gold_base_path}/fact_reviews\")\n",
    "\n",
    "print(\" fact_reviews written to Gold layer\")\n",
    "\n",
    "\n",
    "# 8: Summary & Validation\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" GOLD LAYER BUILD COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n--Dimensional Model Summary:\")\n",
    "print(f\" dim_date:       {df_dim_date.count():,} dates\")\n",
    "print(f\" dim_categories: {df_dim_categories.count():,} categories\")\n",
    "print(f\" dim_products:   {df_dim_products.count():,} products\")\n",
    "print(f\" dim_users:      {df_dim_users.count():,} users\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "goldlayer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
